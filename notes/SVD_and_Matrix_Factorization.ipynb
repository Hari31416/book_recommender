{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"..\", \"data\", \"final_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 104756\n",
      "Number of unique users: 31940\n",
      "Number of books: 22020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>provided_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0891075275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0553264990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0449005615</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>0671888587</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>1853260053</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        isbn  provided_rating\n",
       "0       17  0891075275                6\n",
       "1       17  0553264990                5\n",
       "2       26  0449005615                9\n",
       "3       39  0671888587                7\n",
       "4       69  1853260053                8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(DATA_DIR, 'ratings.parquet'))\n",
    "books= pd.read_parquet(os.path.join(DATA_DIR, 'books_all.parquet'))\n",
    "df = df[df[\"isbn\"].isin(books[\"isbn\"])]\n",
    "df = df.query(\"provided_rating!=0\")\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Number of ratings: {len(df)}\")\n",
    "print(f\"Number of unique users: {df['user_id'].nunique()}\")\n",
    "print(f\"Number of books: {df['isbn'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn\n",
       "0316666343    707\n",
       "0060928336    320\n",
       "0671027360    269\n",
       "067976402X    256\n",
       "0786868716    242\n",
       "Name: provided_rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ratings = df.groupby('isbn')['provided_rating'].count().sort_values(ascending=False)\n",
    "most_rated_books = num_ratings.index[:10]\n",
    "num_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "11676     1593\n",
       "98391      595\n",
       "189835     371\n",
       "76499      333\n",
       "153662     322\n",
       "          ... \n",
       "59675        1\n",
       "157184       1\n",
       "59685        1\n",
       "59697        1\n",
       "278854       1\n",
       "Name: provided_rating, Length: 31940, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id')['provided_rating'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provided_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002163578</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002190915</th>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002210479</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002222469</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002241358</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            provided_rating  num_ratings\n",
       "isbn                                    \n",
       "0002163578              5.0            1\n",
       "0002190915              9.5            2\n",
       "0002210479              6.0            1\n",
       "0002222469              8.0            1\n",
       "0002241358              8.0            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.DataFrame(df.groupby('isbn')['provided_rating'].mean())\n",
    "ratings['num_ratings'] = pd.DataFrame(df.groupby('isbn')['provided_rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books_ with more than 5 ratings: 3823\n",
      "Original number of books_: 22020\n",
      "Number of rows in the original dataset: 104756\n",
      "Number of rows in the new dataset: 72190\n"
     ]
    }
   ],
   "source": [
    "min_ratings = 5\n",
    "books_ = ratings.query(f\"num_ratings > {min_ratings}\").index\n",
    "print(f\"Number of books_ with more than {min_ratings} ratings: {len(books_)}\")\n",
    "print(f\"Original number of books_: {df['isbn'].nunique()}\")\n",
    "print(f\"Number of rows in the original dataset: {df.shape[0]}\")\n",
    "df_small = df[df['isbn'].isin(books_)]\n",
    "print(f\"Number of rows in the new dataset: {df_small.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books_ with more than 10 ratings: 1963\n",
      "Original number of books_: 22020\n",
      "Number of rows in the original dataset: 104756\n",
      "Number of rows in the new dataset: 58166\n",
      "Number of unique users in the new dataset: 22560\n"
     ]
    }
   ],
   "source": [
    "min_ratings = 10\n",
    "books_ = ratings.query(f\"num_ratings > {min_ratings}\").index\n",
    "print(f\"Number of books_ with more than {min_ratings} ratings: {len(books_)}\")\n",
    "print(f\"Original number of books_: {df['isbn'].nunique()}\")\n",
    "print(f\"Number of rows in the original dataset: {df.shape[0]}\")\n",
    "df_small = df[df['isbn'].isin(books_)]\n",
    "unique_users = df_small['user_id'].nunique()\n",
    "print(f\"Number of rows in the new dataset: {df_small.shape[0]}\")\n",
    "print(f\"Number of unique users in the new dataset: {unique_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 22560\n",
      "Num of Movies: 1963\n"
     ]
    }
   ],
   "source": [
    "n_users = df_small.user_id.nunique()\n",
    "n_items = df_small.isbn.nunique()\n",
    "\n",
    "print('Num. of Users: '+ str(n_users))\n",
    "print('Num of Movies: '+str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_14176\\1030253374.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small[\"user_id\"] = df_small[\"user_id\"].map(user_id_map)\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_14176\\1030253374.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small[\"isbn\"] = df_small[\"isbn\"].map(book_id_map)\n"
     ]
    }
   ],
   "source": [
    "user_id_map = dict(zip(df_small.user_id.unique(), list(range(n_users))))\n",
    "book_id_map = dict(zip(df_small.isbn.unique(), list(range(n_items))))\n",
    "user_id_map_df  = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\":user_id_map.keys(),\n",
    "        \"user_id_new\": user_id_map.values(),\n",
    "    }\n",
    ")\n",
    "book_id_map_df  = pd.DataFrame(\n",
    "    {\n",
    "        \"isbn\":book_id_map.keys(),\n",
    "        \"isbn_new\": book_id_map.values(),\n",
    "    }\n",
    ")\n",
    "df_small[\"user_id\"] = df_small[\"user_id\"].map(user_id_map)\n",
    "df_small[\"isbn\"] = df_small[\"isbn\"].map(book_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix. The SVD of an $n\\times m$ complex matrix $\\mathbf{M}$ is a factorization of the form\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^*\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\mathbf{U}$ is an $n\\times m$ unitary matrix over the field $\\mathbb{C}$, called the left singular vectors of $\\mathbf{M}$,\n",
    "\n",
    "$\\mathbf{\\Sigma}$ is an $m\\times m$ diagonal matrix with non-negative real numbers on the diagonal, called the singular values of $\\mathbf{M}$,\n",
    "\n",
    "and $\\mathbf{V}^*$ denotes the conjugate transpose of an $n\\times n$ unitary matrix $\\mathbf{V}$ over $\\mathbb{C}$, called the right singular vectors of $\\mathbf{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the matrix $\\mathbf{M}$ is real, $\\mathbf{V}^*$ denotes the transpose of $\\mathbf{V}$ and we can denote the SVD of a real matrix with\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "Furthermore, for this case, $\\mathbf{U}$ and $\\mathbf{V}$ form two sets of orthonormal bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singular values are ordered such that $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_p \\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Imagine we collected some book reviews such that books are columns and people are rows, and the entries are the ratings that a person gave to a book. In that case, $\\mathbf{M}\\cdot \\mathbf{M}^T$ would be a table of person-to-person which the entries would mean the sum of the ratings one person gave match with another one. Similarly $\\mathbf{M}^T\\cdot \\mathbf{M}$ would be a table of book-to-book which entries are the sum of the ratings received match with that received by another book. What can be the hidden connection between people and books? That could be the genre, or the author, or something of similar nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low rank approximation with the SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank of a matrix, $\\mathbf{A}$, is determined by the dimension of the vector space spanned by its columns. The SVD can be used to approximate a matrix with a lower rank, which ultimately decreases the dimensionality of data required to store the information represented by the matrix. The rank-r approximation of $\\mathbf{A}$ in terms of the SVD is defined by the formula:\n",
    "\n",
    "$$\n",
    "{\\mathrm{A_r} } = {\\mathrm{U_r} } \\Sigma_r {\\mathrm{V_r} }^T\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathbf{U_r}$ is the $m\\times r$ matrix consisting of the first $r$ columns of $\\mathbf{U}$,\n",
    "\n",
    "$\\mathbf{\\Sigma_r}$ is the $r\\times r$ diagonal matrix consisting of the first $r$ singular values of $\\mathbf{A}$,\n",
    "\n",
    "and $\\mathbf{V_r}$ is the $n\\times r$ matrix consisting of the first $r$ columns of $\\mathbf{V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVD for Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a matrix of user-to-item ratings, and we can use SVD decomposition to create two new matrices that can be used to predict unknown ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22560, 1963)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = df_small.pivot_table(index='user_id', columns='isbn', values='provided_rating')\n",
    "M = M.fillna(0)\n",
    "M = M.values\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 22560 users and 1963 books. In notation denoted above, we have $n = 22560$ and $m = 1963$. We can use `numpy.svd` to decompose the matrix into three matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22560, 1963), (1963,), (1963, 1963))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, sigma, Vt = svd(M, full_matrices=False)\n",
    "U.shape, sigma.shape, Vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if it approximates the original matrix well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(M, M_hat, threhsold = 0.5):\n",
    "    M_copy = M.copy()\n",
    "    M_copy = M_copy[M_hat > threhsold]\n",
    "    M_hat_copy = M_hat.copy()\n",
    "    M_hat_copy = M_hat_copy[M_hat > threhsold]\n",
    "    print(f\"Number of ratings: {len(M)}\")\n",
    "    return np.sqrt(np.mean((M - M_hat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 22560\n",
      "RMSE: 1.2170026062959825e-15\n"
     ]
    }
   ],
   "source": [
    "M_ = np.dot(U, np.dot(np.diag(sigma), Vt))\n",
    "rmse = calculate_rmse(M, M_, threhsold=0.5)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! The problem is, the matrices still have very high dimensions. We can use the low rank approximation to reduce the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_r: (22560, 100)\n",
      "s_r: (100,)\n",
      "V_r: (100, 1963)\n"
     ]
    }
   ],
   "source": [
    "r = 100\n",
    "s_r, U_r, V_r = sigma[..., :r], U[..., :, :r], Vt[..., :, :r].T\n",
    "print(f\"U_r: {U_r.shape}\")\n",
    "print(f\"s_r: {s_r.shape}\")\n",
    "print(f\"V_r: {V_r.shape}\")\n",
    "M_r = np.dot(U_r, np.dot(np.diag(s_r), V_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation Size: 490480\n",
      "Original Size: 48140612\n",
      "Compression Ratio: 98.15\n"
     ]
    }
   ],
   "source": [
    "def rank_r_approx(s, U, V, r, verbose=False):\n",
    "  s_r, U_r, V_r = s[..., :r], U[..., :, :r], V[..., :, :r].T #need to transpose V\n",
    "  # Compute the low-rank approximation and its size\n",
    "  M_r = np.dot(U_r, np.dot(np.diag(s_r), V_r))\n",
    "  M_r_size = np.size(U_r) + np.size(s_r) + np.size(V_r)\n",
    "  og_size = np.size(U) + np.size(s) + np.size(V)\n",
    "  if verbose:\n",
    "    print(f\"Approximation Size: {M_r_size}\")\n",
    "    print(f\"Original Size: {og_size}\")\n",
    "    print(f\"Compression Ratio: {og_size/M_r_size}\")\n",
    "  return M_r, M_r_size\n",
    "\n",
    "M_r, M_r_size = rank_r_approx(sigma, U, Vt, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using rank of 20 gives a compression ratio of about 100. Let us check the RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 22560\n",
      "RMSE: 0.30479232583716404\n"
     ]
    }
   ],
   "source": [
    "rmse = calculate_rmse(M, M_r, threhsold=0.5)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the RMSE has increased. This was expected, since we are using a lower rank approximation. However, the RMSE is still very low, and we have reduced the dimensions of the matrices by a factor of 20. This is a huge improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD, discussed above is a special case of matrix factorization. Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices. The matrix factorization algorithms are usually more scalable than the neighborhood methods and can deal better with sparsity in the user-item matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In matrix factorizations, the user-item interactions are modeled as inner products in the latent factor space with dimensionality $f$. For each item, we have a vector $q_i \\in \\mathbb{R}^f$ which represents the item in the latent factor space. For each user, we have a vector $p_u \\in \\mathbb{R}^f$ which represents the user in the same latent factor space. The rating $r_{ui}$ is the inner product of the corresponding vectors in the latent factor space:\n",
    "\n",
    "$$\n",
    "r_{ui} \\approx q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually need to add some biases to the model. For example, some users may tend to give higher ratings than others, regardless of the items. Thus ratings alone cannot determine what movies should be recommended and that is when biases are added to the equation. The first order approximation of this bias is:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + q_i^Tp_u\n",
    "$$\n",
    "\n",
    "where $\\mu$ is the average rating over all items, $b_u$ is the bias of user $u$, and $b_i$ is the bias of item $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the ratings and biases discussed prior, we must take into account many of the other forms of inputs that affect the outcome of the recommendation. These inputs are generally made up of the implicit data. For example, the time of day, the day of the week, the location of the user, the device being used, the weather, etc. are all examples of implicit data that can be used to improve the recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate this, we can define another vector $x_i \\in \\mathbb{R}^d$ for each item $i$. Furthermore, we can also use some attributes of users such as income, gender, age, etc. to define a vector $y_a \\in \\mathbb{R}^d$ for each user $a$. The rating can then be modeled as:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + q_i^T(p_u + x_i + y_u)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can make these biases as a function of time to incorporate the idea that people's tastes change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be learned by minimizing the regularized squared error on the set of known ratings. We can define the loss function as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda \\left( \\sum_u ||p_u||^2 + \\sum_i ||q_i||^2 + \\sum_i ||x_i||^2 + \\sum_u ||y_u||^2 \\right)\n",
    "$$\n",
    "\n",
    "where $\\mathcal{K}$ is the set of known ratings and $\\lambda$ is the regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In shorthand, we have:\n",
    "\n",
    "$$\n",
    "e_{ui} = r_{ui} - \\mathbf{q}_i^T \\mathbf{p}_u\n",
    "$$\n",
    "\n",
    "then we modify the vectors as:\n",
    "\n",
    "$$\n",
    "\\mathbf{p}_u \\leftarrow \\mathbf{p}_u + \\gamma (e_{ui} \\mathbf{q}_i - \\lambda \\mathbf{p}_u) \\\\\n",
    "\\mathbf{q}_i \\leftarrow \\mathbf{q}_i + \\gamma (e_{ui} \\mathbf{p}_u - \\lambda \\mathbf{q}_i)\n",
    "$$\n",
    "\n",
    "where $\\gamma$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods to learn the parameters:\n",
    "\n",
    "1. Stochastic Gradient Descent (SGD)\n",
    "2. Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD is a generic method that can be used to learn any model. What makes this method less than ideal in this situation is that the error function above is not convex for both $p_u$ and $q_i$ simultaneously. This means that the error function is not bowl shaped, and there are many local minima. This means that SGD can get stuck in a local minimum and not find the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where ALS comes in. ALS is a method that can be used to learn the parameters of a matrix factorization model. ALS works by holding one set of parameters constant and optimizing the other. Then the roles are reversed and the other set of parameters are optimized while the other set is held constant. This process is repeated until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD and User-Item Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already discussed that the SVD of the user-item matrix $\\mathbf{M}$ is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we can approximate:\n",
    "\n",
    "$$\n",
    "\\mathbf{p}_u \\approx \\mathbf{U}_k\\sqrt{\\mathbf{\\Sigma}}^T \\\\\n",
    "\\mathbf{q}_i \\approx \\sqrt{\\mathbf{\\Sigma}}\\mathbf{V}_k^T\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
